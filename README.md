# README

**Обнаружение объектов с помощью PyTorch Faster RCNN ResNet50 FPN V2, обученный наборам данных PPE**

### Предварительная подготовка Backbone ResNet50

Предварительная подготовка Backbone ResNet50 является важной задачей для повышения производительности всей модели обнаружения объектов. Модель ResNet50 (как и многие другие модели классификации) была обучена с использованием нового рецепта обучения. К ним относятся, но не ограничиваются ими:

* Оптимизация скорости обучения.
* Более длительное обучение.
* Дополнения, такие как TrivialAugment, случайное стирание, MixUp и CutMix.
* Повторное увеличение
* EMA
* Настройка уменьшения веса

Благодаря этим новым технологиям точность ResNet50 @ 1 возрастает до 80,858% с прежних 76,130%.

Обучение более быстрой модели RCNN ResNet50 FPN V2
Как упоминалось ранее, большинство улучшений для обучения всей модели обнаружения объектов были взяты из вышеупомянутой статьи.

Авторы этих улучшений называют их улучшениями в соответствии с оптимизацией после публикации статьи. К ним относятся:

* FPN с пакетной нормализацией.
* Использование двух сверточных уровней в сети Region Proposal * (RPN) вместо одного. Другими словами, использование более мощного модуля FPN.
* Используя более массивную головку регрессии. Если быть точным, используя четыре сверточных слоя с пакетной нормализацией, за которыми следует линейный слой. Ранее использовалась двухслойная MLP-головка без пакетной нормализации.
* Нормализации замороженных пакетов не использовались.

Использование приведенного выше рецепта улучшает карту с предыдущих 37,0% до 46,7%, что дает колоссальное увеличение карты на 9,7%.

## Структура каталогов

* Папка data содержит набор данных для этого проекта в папке data / ppe. Папки train и test содержат изображения вместе с файлами XML.
* Каталог data_configs содержит информацию о наборе данных и конфигурацию. Мы рассмотрим это позже в этом посте.

У нас есть скрипт для двух моделей в каталоге models. Один предназначен для более старой Faster RCNN ResNet50 FPN, а другой - для FPN V2. Мы можем использовать любой из них во время обучения, просто изменив одно значение флага командной строки.

* Каталог выходных данных будет содержать все выходные данные обучения.

У нас есть torch_utils и каталог utils, который содержит множество вспомогательного кода и обучающих утилит. Мы не будем здесь углубляться в их детали. Но вы можете сами ознакомиться с ними.

* Также есть два сценария вывода, один для вывода изображений и один для вывода видео. Наряду с этим, у нас есть datasets.py для подготовки набора данных и загрузчиков данных. The train.py - исполняемый скрипт для запуска обучения.

#### Обучите более быструю модель RCNN

`python train.py --model fasterrcnn_resnet50_fpn_v2 --config data_configs/ppe.yaml --epochs 50 --project-name fasterrcnn_resnet50_fpn_v2_ppe --use-train-aug --no-mosaic`

Ниже приведены аргументы командной строки, которые мы используем:

* --model: Здесь мы используем fasterrcnn_resnet50_fpn_v2, чтобы указать, что мы хотим обучить новую более быструю модель RCNN. Для обучения старой модели вы можете просто указать значение как fasterrcnn_resnet50_fpn .
* --config: он принимает путь к файлу конфигурации набора данных, который в данном случае является файлом data / ppe.yaml.
* --эпохи: Мы обучаем модель для 50 эпох.
* --project-name: Предоставление строкового значения этому аргументу сохранит результаты с этим именем папки внутри outputs/ training . В этом случае это будут выходные данные / обучение /fasterrcnn_resnet50_fpn_v2_ppe.
* --use-train-aug: загрузчик данных поддерживает различные расширения изображения. Этот аргумент является логическим значением, которое гарантирует, что эти расширения будут применены.
* --no-mosaic: Кроме того, загрузчик данных также поддерживает расширение мозаики. Но предоставление этого логического аргумента отключит его.

#### Выполняется detect_video.py для вывода видео

`python inference_video.py --weights outputs/training/fasterrcnn_resnet50_fpn_v2_ppe/best_model.pth --input data/inference_data/video_1.mp4 --show-image --threshold 0.9`

Ниже приведены аргументы командной строки:

* --weights: путь к файлу weights. Здесь мы используем наиболее подготовленные веса.
* --input: путь к исходному видео. Вы также можете указать путь к своим собственным видео.
* --показать-изображение: это сообщает скрипту, что мы хотим визуализировать результаты на экране.
* --threshold: Мы используем доверительный порог в 90% для визуализаций.
